---
title: 'Appendix E: Analysis pipeline'
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Introduction
============

This knitr document...

1. Generates random data with the same shape as the
data we will collect in our replication (for details of how the data is
generated, see the custom function defined in `generate_data_fnc.R`). The data
is generated with a fixed random seed for reproducibility.
2. Analyzes the simulated data in the same way we will analyze our actual data.


Set up workspace
===============

```{r, message=FALSE}
library("knitr")
library("brms")
library("tidyverse")
library("sjPlot")
library("sjlabelled")
library("moments")
```


Model from the re-analysis of original data:

```{r}
# Load brms model fitted to original data
bfm_orig <- readRDS("data/bayes_glmm_normprior_interact.rds")
```

Extract posterior for interaction coefficient to use later as prior for
replication BF:

```{r}
# Extract posterior estimates for the critical interaction effect from the brms
# model (pull converts it to a numerical vector):
beta_posterior <- pull(posterior_samples(bfm_orig, "movementarm_vs_leg:word_typearm_vs_leg"))
# check normality
qqnorm(beta_posterior)
qqline(beta_posterior,col='red')
moments::kurtosis(beta_posterior)
moments::skewness(beta_posterior)
# We will assume normality here. Note that it is misleading (some say pointless)
# to check for normality with very large vectors, see
# https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless
mean_inter_post <- mean(beta_posterior)
sd_inter_post   <- sd(beta_posterior)
```


```{r}
# Load simulate_binom() function
source("generate_data_fnc.R")
```


Generate data
============

Set simulation parameters
------------------------

The arguments we need to pass to `simulate_binom()` specify different parameters
of the statistical model that generates the data.
We take those parameters from the original data whenever we can and we make up
the rest using common sense.


```{r}
# Fixed effects
# Vector of coefficient means
fixef_means <- fixef(bfm_orig)[, 1]
fixef_means
```


```{r}
# Covariance matrix (Sigma); we need to square the SEs to convert them to Variances
fixef_sigma <- diag(fixef(bfm_orig)[, 2]) ^ 2  # we assume uncorrelated diagonal matrix
fixef_sigma
```


```{r}
# For random effects by subject we only have an estimate of the random intercept:
VarCorr(bfm_orig)
# We will assume that SDs for the other parameters (random slopes) are
# proportional to the corresponding fixef SEM in the same way the intercept is:
prop <- VarCorr(bfm_orig)$subject$sd[1] / fixef(bfm_orig)[1, 2]  # random variability >3 times SEM
# again assume uncorrelated diagonal matrix:
ranef_sigma_subj <- diag(fixef(bfm_orig)[, 2] * prop) ^ 2  
ranef_sigma_subj
# However, by-subject variance for random slopes of the critical interaction we
# set to be somewhat larger, reflecting individual variability for the effect.
ranef_sigma_subj[4,4] <- 0.2 ^ 2
ranef_sigma_subj  # variances
sqrt(ranef_sigma_subj)  # SDs are probably more intuitive to think of
```


```{r}
# Random effects by item we need to completely make up. We let SD for the intercept
# and Movement conditions be the same as the corresponding by-subject SDs.
# assume uncorrelated diagonal matrix:
ranef_sigma_item <- diag(fixef(bfm_orig)[1:2, 2] * prop) ^ 2  
ranef_sigma_item
```


Simulate data
-------------

Simulate data for our $maxN=96$:

```{r, message=FALSE}
# Simulate data
set.seed(654198461)  # make data set replicable
d_list <- simulate_binom(
  Nsubj = 96,
  Nitem = 104,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item,
  full_output = TRUE,
  print_each_step = FALSE
)
```


The output consists of a list of data frames containing the data as well as
information about the parameters that generated the data.

```{r}
names(d_list)
```


The 1st element in the list contains the data frame with the simulated data:

```{r}
# First list contains the actual data set
d <- d_list[[1]]
head(d) %>% kable
```

This data frame contains columns that decompose each observation into the
parameters that generated it. These parameters reflect effects at three different
levels: population-, subject-, and participant-level effects.

In the actual data set we would only observe the actual outcome and would have
to infer the rest. So the actual data will look like this:

```{r}
d %>% select(subject : Error) %>% head %>% kable
```


Show the (six first rows of the) other objects in the list:

```{r}
lapply(d_list[2:7], function(x) x %>% head %>% kable)
```




Simulate sequential data collection
-----------------------------------

Our design is sequential:

1. Collect data from $minN=60$ participants.
2. Compute $BF$ for alternative hypothesis (interaction $\neq 0$) vs null hypothesis (interaction $= 0$)
3. If either $BF_{10} > 6$ or $BF_{01} > 6$, stop data collection and report results. Else:
4. If $N<96$, collect another batch of 12 participants and go to step 2. Else:
5. When we reach $N=96$, stop data collection, compute $BF$ and report results.


We therefore split the data into batches:

```{r}
d_60 <- d %>% filter(subject %in% 1 : 60)
d_72 <- d %>% filter(subject %in% 1 : 72)
d_84 <- d %>% filter(subject %in% 1 : 84)
d_96 <- d %>% filter(subject %in% 1 : 96)
```


Analyze and plot data
=====================

Create a function that streamlines data processing and model fitting:

```{r}
analyse_pipe <- function(
  df,            # expects the data frame in above format
  repBF = FALSE  # compute replication BF?
  ) {
  
  df_name <- deparse(substitute(df))  # to use for filename later
  if (repBF) { df_name <- paste(df_name, "repBF", sep = "_") }
  
  # Drop superfluous columns (those that won't be in the actual data)
  df <- select(df, subject : Error)

  # coding scheme: contrast code factors and standardize numerical predictors
  contrasts(df$movement) <- contr.sum(2)
  colnames(contrasts(df$movement)) <- "arms_vs_legs"
  print(contrasts(df$movement))
  
  contrasts(df$word_type) <- contr.sum(2)
  colnames(contrasts(df$word_type)) <- "arms_vs_legs"
  print(contrasts(df$word_type))
  
  df$trial_in_exp_z <- scale(df$trial_in_exp)
  df$pos_in_trial_z <- scale(df$pos_in_trial)
  df$preced_error_z <- scale(df$preced_error)

  # As default, specify weakly informative priors: N(0,sigma^2 = 4) for
  # population-level (fixed) effects
  # NB: In Stan a normal distribution is specified with sigma (*not* sigma^2), see
  # https://mc-stan.org/docs/2_18/functions-reference/normal-distribution.html
  # and
  # https://stackoverflow.com/questions/52893379/stan-in-r-standard-deviation-or-variance-in-normal-distribution
  myprior <- set_prior("normal(0, 2)", class = "b")
  print(myprior)
  # for replication BF, use the posterior of the re-analysis as prior for interaction:
  myprior_repBF <- c(
    myprior,
    set_prior("normal(0.149, 0.0418)", class = "b",
              coef = "movementarms_vs_legs:word_typearms_vs_legs")
    )
  print(myprior_repBF)

  # Model *without* interaction
  # NB: for the replication BF, we need now to remove prior for interaction
  # (which is not defined in the model):
  bfm_binom_nointeract <- brm(
    Error ~
      1 + movement + word_type +  # critical manipulations but no interaction
      trial_in_exp_z + pos_in_trial_z + preced_error_z +  # nuisance predictors
      (1 + movement * word_type | subject) + (1 + movement | item),  # maximal random structure
    data = df,
    prior = myprior,
    family = "bernoulli",
    iter = 15000, warmup = 2000, chains = 4,  # https://discourse.mc-stan.org/t/bayes-factor-using-brms/4469/3
    save_all_pars = TRUE  # necessary for brms::bayes_factor() later
  )
  
  # fit full model (with interaction):
  bfm_binom <- brm(
    Error ~
      1 + movement * word_type +  # critical manipulations and interaction
      trial_in_exp_z + pos_in_trial_z + preced_error_z +  # nuisance predictors
      (1 + movement * word_type | subject) + (1 + movement | item),  # maximal random structure
    data = df,
    prior = if (repBF) { myprior_repBF } else { myprior },
    family = "bernoulli",
    iter = 15000, warmup = 2000, chains = 4,  # https://discourse.mc-stan.org/t/bayes-factor-using-brms/4469/3
    save_all_pars = TRUE  # necessary for brms::bayes_factor() later
  )
  
  # pack models and data into a list and give sensible names to each object
  out <- list(bfm_binom, bfm_binom_nointeract, df)
  names(out) <- paste(df_name, c("bfm_full", "bfm_nointer", "dataset"), sep = "_")

  # save list to disk:
  saveRDS(out, file = paste("data/analysis_simulated_", df_name, ".rds", sep =""))
  
  out
}
```


At $N=60$
---------

### Fit models

```{r}
# sim_d_60 <- analyse_pipe(d_60)  # takes about 2.5 hours
sim_d_60 <- readRDS("data/analysis_simulated_d_60.rds")
names(sim_d_60)
```


### Model summary

Summary of priors:

```{r}
prior_summary(sim_d_60[[1]])
```


```{r}
summary(sim_d_60[[1]])
# summary(sim_d_60[[2]])
```


### Bayes factor

```{r}
# # Run and save to disk
# BF_bfm_d60 <- brms::bayes_factor(
#   sim_d_60[["d_60_bfm_full"]], sim_d_60[["d_60_bfm_nointer"]]
#   )
# saveRDS(BF_bfm_d60, "data/BF_bfm_d60.rds")
```

```{r}
# Once run, read from disk
BF_bfm_d60 <- readRDS("data/BF_bfm_d60.rds")
```

```{r}
BF_bfm_d60
```



### Plot model estimates

Plot all population-level estimates. Inner boxes show 50%, outer error bars 95%
credible intervals (see detailed 
[plot explanation here](https://strengejacke.github.io/sjPlot/articles/plot_model_estimates.html#bayesian-models-fitted-with-stan)): 

```{r}
sjPlot::plot_model(
  sim_d_60[[1]], transform = NULL, prob.outer = .95, sort.est = TRUE,
  vline.color = "gray", title = "Log-odds of error",
  axis.labels = c(  # Careful: indep of sort.est, the order is simply specified bottom to top!
    "word type (arm- vs leg-related)",
    "movement condition (arms vs legs)",
    "preceding error in trial",
    "word position in trial",
    "trial in experiment",
    "movement-by-word type interaction"
    )
  ) +
  theme_classic()
```


Plot the interaction effect:

```{r}
plot(marginal_effects(sim_d_60[[1]], effects = "movement:word_type"),
     theme = theme_classic())
```


### Replication Bayes factor (after Verhagen and Wagenmakers, 2014)

For the replication BF we use as the prior for the interaction the posterior
distribution from the model fitted to the original data. We specify this as
a normal distribution (see "Set up workspace" for this prior).


#### Fit models with appropriate prior for repBF:

```{r}
# sim_d_60_BFrep <- analyse_pipe(d_60, repBF = TRUE)  # takes about  hours
sim_d_60_BFrep <- readRDS("data/analysis_simulated_d_60_repBF.rds")
names(sim_d_60_BFrep)
```

Summary of priors:

```{r}
prior_summary(sim_d_60_BFrep[[1]])
prior_summary(sim_d_60_BFrep[[2]])
```

Model summary

```{r}
summary(sim_d_60_BFrep[[1]])
summary(sim_d_60_BFrep[[2]])
```


#### Replication BF

Replication Bayes factor:

```{r}
# # Run and save to disk
# BFrep_bfm_d60 <- brms::bayes_factor(
#   sim_d_60_BFrep[[1]], sim_d_60_BFrep[[2]]
#   )
# saveRDS(BFrep_bfm_d60, "data/BFrep_bfm_d60.rds")
```

```{r}
# Once run, read from disk
BFrep_bfm_d60 <- readRDS("data/BFrep_bfm_d60.rds")
```

```{r}
BFrep_bfm_d60
```

#### Plots

```{r}
sjPlot::plot_model(
  sim_d_60_BFrep[[1]], transform = NULL, prob.outer = .95, sort.est = TRUE,
  vline.color = "gray", title = "Log-odds of error",
  axis.labels = c(  # Careful: indep of sort.est, the order is simply specified bottom to top!
    "word type (arm- vs leg-related)",
    "movement condition (arms vs legs)",
    "preceding error in trial",
    "word position in trial",
    "trial in experiment",
    "movement-by-word type interaction"
    )
  ) +
  theme_classic()
```


Plot the interaction effect:

```{r}
plot(marginal_effects(sim_d_60_BFrep[[1]], effects = "movement:word_type"),
     theme = theme_classic())
```




Session info
============

```{r}
sessionInfo()
```

