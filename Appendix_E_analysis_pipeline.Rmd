---
title: 'Appendix E: Analysis pipeline'
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Introduction
============

This knitr document...

1. Generates random data with the same shape as the
data we will collect in our replication (for details of how the data is
generated, see the custom function defined in `generate_data_fnc.R`). The data
is generated with a fixed random seed for reproducibility.
2. Analyzes the simulated data in the same way we will analyze our actual data.


Set up workspace
===============

```{r, message=FALSE}
library("knitr")
library("brms")
library("tidyverse")
library("sjPlot")
library("sjlabelled")
library("moments")
```


Model from the re-analysis of original data:

```{r}
# Load brms model fitted to original data. It's a list with three objects: the
# full model is the first element of that list:
bfm_orig <- readRDS("data/sp13_bfm_max.rds")[[1]]
```

Extract posterior for interaction coefficient to use later as prior for
replication BF:

```{r}
# Extract posterior estimates for the critical interaction effect from the brms
# model (pull converts it to a numerical vector):
beta_posterior <- pull(posterior_samples(bfm_orig, "b_mv_wt"))
# check normality
qqnorm(beta_posterior)
qqline(beta_posterior,col='red')
moments::kurtosis(beta_posterior)
moments::skewness(beta_posterior)
# We may safely assume normality. NB: Shapiro test doesn't work if 
# length(v) > 5000, and is problematic for other reasons as well. See:
# https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless
mean_inter_post <- mean(beta_posterior)
mean_inter_post
sd_inter_post   <- sd(beta_posterior)
sd_inter_post
```


```{r}
# Load simulate_binom() function
source("generate_data_fnc.R")
```


Generate data
============

Set simulation parameters
------------------------

The arguments we need to pass to `simulate_binom()` specify different parameters
of the statistical model that generates the data.
We take those parameters from the original data for fixed effects and by-subject
random effects. We use estimates from our pilot data for by-subject intercepts.

The estimates we use are the same as in our power simulations (Appendix C).

```{r}
# Fixed (i.e., population-level) effects:
fixef(bfm_orig)

# Vector of coefficient means for fixed effects
fixef_means <- fixef(bfm_orig)[, 1]
fixef_means

# SEMs for fixed effects. These we take from the covariance matrix (Sigma) of
# the model. Note we need to square the SEMs to convert them to variances, which
# is what our simulate_binom() function expects (rather than SD).
fixef_sigma <- diag(fixef(bfm_orig)[, 2] ^ 2)  # we assume uncorrelated diagonal matrix
fixef_sigma

# By-subject random effects for the model:
VarCorr(bfm_orig)$subject$sd
# Extract by-subject random SDs and square them to obtain variances:
ranef_sigma_subj <- diag(VarCorr(bfm_orig)$subject$sd[, 1]) ^ 2
ranef_sigma_subj

# The original data consists of aggregated by-subject data, not trial-level data.
# To obtain estimates for item-level variability we use our own pilot data (see
# https://github.com/montero-melis/2018_replication_sheb-pulv2013/blob/master/1806_pilot_analysis/item-variance_estimates.R).
# The random by-item intercept is SD=0.65. However, we don't have estimates for
# by-item random slope for movement because we only ran the control condition in
# the pilot. We will assume the SD for this random slope to be the same as the
# by-subject SD for the slope of the critical interaction, which is likely to be
# an overestimate. If so, it will only make our power estimates more conservative:
ranef_sigma_item <- diag(c(0.65, 0.06)) ^ 2  # square to obtain variances
ranef_sigma_item
```



Simulate data
-------------

Simulate data for our $N_{max} = 108$:

```{r, message=FALSE}
# Simulate data
set.seed(654198461)  # make data set replicable
d <- simulate_binom(
  Nsubj = 60,
  Nitem = 104,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item
)
```


The output is a data frame with the simulated data:

```{r}
head(d) %>% kable
```

This data frame contains columns that decompose each observation into the
parameters that generated it. These parameters reflect effects at three different
levels: population-, subject-, and participant-level effects.

In the actual data set we would only observe the actual outcome and would have
to infer the rest. So the actual data will look like this:

```{r}
d %>% select(subject : Error) %>% head %>% kable
```



Simulate sequential data collection
-----------------------------------

Our design is sequential:

1. Collect data from $minN=60$ participants.
2. Compute $BF$ for alternative hypothesis (interaction $\neq 0$) vs null hypothesis (interaction $= 0$)
3. If either $BF_{10} > 6$ or $BF_{01} > 6$, stop data collection and report results. Else:
4. If $N<108$, collect another batch of 12 participants and go to step 2. Else:
5. When we reach $N=108$, stop data collection, compute $BF$ and report results.

We would therefore first analyze a data set of 60 participants:

```{r}
d_60 <- d %>% filter(subject %in% 1 : 60)
```


Analyze and plot data (analysis pipeline)
=====================

We show the data analysis pipeline for a data set corresponding to a sample
size of $N=60$. If the Bayes factor was below hour pre-determined evidence
threshold ($\frac{1}{6} < BF_{10} < 6$), then we would collect an additional
batch of 12 participants and repeat the same analysis.


Function for data analysis
--------------------------

Create a function that streamlines data processing and model fitting:

```{r}
analyse_pipe <- function(
  df,            # expects the data frame in above format
  repBF = FALSE  # compute replication BF?
  ) {
  
  df_name <- deparse(substitute(df))  # to use for filename later
  if (repBF) { df_name <- paste(df_name, "repBF", sep = "_") }
  
  # Drop superfluous columns (those that won't be in the actual data)
  df <- select(df, subject : Error)

  # coding scheme: contrast code factors and standardize numerical predictors
  contrasts(df$movement) <- contr.sum(2)
  colnames(contrasts(df$movement)) <- "arms_vs_legs"
  print(contrasts(df$movement))
  
  contrasts(df$word_type) <- contr.sum(2)
  colnames(contrasts(df$word_type)) <- "arms_vs_legs"
  print(contrasts(df$word_type))
  
  df$trial_in_exp_z <- scale(df$trial_in_exp)
  df$pos_in_trial_z <- scale(df$pos_in_trial)
  df$preced_error_z <- scale(df$preced_error)
  
  # Priors:
  # As default, specify weakly informative priors: N(0,sigma^2 = 4) for
  # population-level (fixed) effects
  # NB: In Stan a normal distribution is specified with sigma (*not* sigma^2), see
  # https://mc-stan.org/docs/2_18/functions-reference/normal-distribution.html
  # and
  # https://stackoverflow.com/questions/52893379/stan-in-r-standard-deviation-or-variance-in-normal-distribution
  formula_full <- as.formula(paste(
    "Error ~",  # DV
    "1 + movement * word_type +",  # critical manipulations and interaction
    "trial_in_exp_z + pos_in_trial_z + preced_error_z +",  # nuisance predictors
    "(1 + movement * word_type | subject) + (1 + movement | item)"  # maximal random structure
  ))
  print(formula_full)
  print(get_prior(formula_full, df))
  
  formula_null <- update(formula_full, ~ . - movement : word_type)
  print(formula_null)
  print(get_prior(formula_null, df))

  myprior <- set_prior("normal(0, 2)", class = "b")
  print("myprior:")
  print(myprior)
  # for replication BF, use the posterior of the re-analysis as prior for interaction:
  myprior_repBF <- c(
    myprior,
    set_prior(
      paste("normal(", mean_inter_post, ",", sd_inter_post, ")", sep = ""),
      class = "b",
      coef = "movementarms_vs_legs:word_typearms_vs_legs"
      )
    )
  print("myprior_repBF:")
  print(myprior_repBF)

  # fit null model (without interaction):
  # NB: The prior for interaction is not defined in the null model:
  bfm_null <- brm(
    formula = formula_null,
    data = df,
    prior = myprior,
    family = "bernoulli",
    iter = 15000, warmup = 2000, chains = 4,  # https://discourse.mc-stan.org/t/bayes-factor-using-brms/4469/3
    save_all_pars = TRUE  # necessary for brms::bayes_factor() later
  )
  # Model *without* interaction
  bfm_full <- update(
    bfm_null,
    formula = formula_full,
    prior = if (repBF) { myprior_repBF } else { myprior },
    )

  # pack models and data into a list and give sensible names to each object
  out <- list(bfm_full, bfm_null, df)
  names(out) <- paste(df_name, c("bfm_full", "bfm_null", "dataset"), sep = "_")

  # save list to disk:
  saveRDS(out, file = paste("data/analysis_simulated_", df_name, ".rds", sep =""))
  
  out
}
```



Fit models
----------


```{r}
sim_d_60 <- analyse_pipe(d_60)  # takes about 2.5 hours
# sim_d_60 <- readRDS("data/analysis_simulated_d_60.rds")
names(sim_d_60)
```

Summary of priors:

```{r}
prior_summary(sim_d_60[[1]])
```


Model summary
------------

Full model with the critical interaction:

```{r}
summary(sim_d_60[[1]])
```


Bayes factor
------------

Compute Bayes factor (or load from disk):

```{r}
# Run and save to disk
BF_bfm_d60 <- brms::bayes_factor(
  sim_d_60[["d_60_bfm_full"]], sim_d_60[["d_60_bfm_null"]]
  )
# saveRDS(BF_bfm_d60, "data/BF_bfm_d60.rds")
```

```{r}
# Once run, read from disk
BF_bfm_d60 <- readRDS("data/BF_bfm_d60.rds")
```


Actual Bayes factor comparing $H_1$ (the critical interaction is not zero) to 
$H_0$ (the critical interaction is zero):

```{r}
BF_bfm_d60
```



Plot model estimates
--------------------

Plot all population-level estimates. Inner boxes show 50%, outer error bars 95%
credible intervals (see detailed 
[plot explanation here](https://strengejacke.github.io/sjPlot/articles/plot_model_estimates.html#bayesian-models-fitted-with-stan)): 

```{r}
sjPlot::plot_model(
  sim_d_60[[1]], transform = NULL, prob.outer = .95, sort.est = TRUE,
  vline.color = "gray", title = "Log-odds of error",
  axis.labels = c(  # Careful: indep of sort.est, the order is simply specified bottom to top!
    "word type (arm- vs leg-related)",
    "movement condition (arms vs legs)",
    "preceding error in trial",
    "word position in trial",
    "trial in experiment",
    "movement-by-word type interaction"
    )
  ) +
  theme_classic()
```


Plot the interaction effect:

```{r}
plot(marginal_effects(sim_d_60[[1]], effects = "movement:word_type"),
     theme = theme_classic())
```


Replication Bayes factor (after Verhagen and Wagenmakers, 2014)
---------------------------------------------------------------

If the standard BF is above the pre-determined evidence threshold *or* 
if we have reached $maxN=96$,
then we also compute the replication Bayes factor (Verhagen and Wagenmakers, 2014).

For the replication BF we use as the prior for the interaction the posterior
distribution from the model fitted to the original data. We specify this as
a normal distribution (see "Set up workspace" for this prior).


### Fit models with appropriate prior for repBF:

```{r}
# sim_d_60_BFrep <- analyse_pipe(d_60, repBF = TRUE)  # takes about 2  hours
sim_d_60_BFrep <- readRDS("data/analysis_simulated_d_60_repBF.rds")
names(sim_d_60_BFrep)
```

Summary of priors:

```{r}
prior_summary(sim_d_60_BFrep[[1]])
prior_summary(sim_d_60_BFrep[[2]])
```

Model summary (full model with interaction)

```{r}
summary(sim_d_60_BFrep[[1]])
# summary(sim_d_60_BFrep[[2]])
```


### Replication BF

Replication Bayes factor:

```{r}
# # Run and save to disk
# BFrep_bfm_d60 <- brms::bayes_factor(
#   sim_d_60_BFrep[[1]], sim_d_60_BFrep[[2]]
#   )
# saveRDS(BFrep_bfm_d60, "data/BFrep_bfm_d60.rds")
```

```{r}
# Once run, read from disk
BFrep_bfm_d60 <- readRDS("data/BFrep_bfm_d60.rds")
```

Actual $BF_{rep}$:

```{r}
BFrep_bfm_d60
```

### Plots

```{r}
sjPlot::plot_model(
  sim_d_60_BFrep[[1]], transform = NULL, prob.outer = .95, sort.est = TRUE,
  vline.color = "gray", title = "Log-odds of error",
  axis.labels = c(  # Careful: indep of sort.est, the order is simply specified bottom to top!
    "word type (arm- vs leg-related)",
    "movement condition (arms vs legs)",
    "preceding error in trial",
    "word position in trial",
    "trial in experiment",
    "movement-by-word type interaction"
    )
  ) +
  theme_classic()
```


Plot the interaction effect:

```{r}
plot(marginal_effects(sim_d_60_BFrep[[1]], effects = "movement:word_type"),
     theme = theme_classic())
```




Session info
============

```{r}
sessionInfo()
```

