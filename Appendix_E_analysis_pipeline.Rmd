---
title: 'Appendix E: Analysis pipeline'
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Introduction
============

This knitr document...

1. Generates random data with the same shape as the
data we will collect in our replication (for details of how the data is
generated, see the custom function defined in `generate_data_fnc.R`). The data
is generated with a fixed random seed for reproducibility.
2. Analyzes the simulated data in the same way we will analyze our actual data.

*NB:*

In our experiment we will collect data from three conditions, the two critical
conditions (arm movement and leg movement) and the control condition (during
which participants do not perform any movement). The latter only serves quality
checks (see manuscript) and will not be part of our critical analysis. We will
subset the data to only analyze the critical conditions. In our simulations
below we only simulate these critical conditions.


Set up workspace
===============

```{r, message=FALSE}
library("knitr")
library("brms")
library("tidyverse")
library("sjPlot")
library("sjlabelled")
library("moments")
```


Load the model fitted to the original data (see re-analysis - Appendix B):

```{r}
# Load brms model fitted to original data. It's a list with three objects: the
# full model is the first element of that list:
bfm_orig <- readRDS("data/sp13_bfm_max.rds")[[1]]
```

Extract posterior for interaction coefficient to use later as prior for
replication BF:

```{r}
# Extract posterior estimates for the critical interaction effect from the brms
# model (pull converts it to a numerical vector):
beta_posterior <- pull(posterior_samples(bfm_orig, "b_mv_wt"))
# check normality
qqnorm(beta_posterior)
qqline(beta_posterior,col='red')
moments::kurtosis(beta_posterior)
moments::skewness(beta_posterior)
# We may safely assume normality. NB: Shapiro test doesn't work if 
# length(v) > 5000, and is problematic for other reasons as well. See:
# https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless
mean_inter_post <- mean(beta_posterior)
mean_inter_post
sd_inter_post   <- sd(beta_posterior)
sd_inter_post
```


```{r}
# Load simulate_binom() function
source("generate_data_fnc.R")
```


Generate data
============

Set simulation parameters
------------------------

The arguments we need to pass to `simulate_binom()` specify different parameters
of the statistical model that generates the data.
We take those parameters from the original data for fixed effects and by-subject
random effects. We use estimates from our pilot data for by-subject intercepts.
Note that the estimates we use here are the same as in our design analysis /
power simulations (Appendix C).

```{r}
# Fixed (i.e., population-level) effects:
fixef(bfm_orig)

# Vector of coefficient means for fixed effects
fixef_means <- fixef(bfm_orig)[, 1]
fixef_means

# SEMs for fixed effects. These we take from the covariance matrix (Sigma) of
# the model. Note we need to square the SEMs to convert them to variances, which
# is what our simulate_binom() function expects (rather than SD).
fixef_sigma <- diag(fixef(bfm_orig)[, 2] ^ 2)  # we assume uncorrelated diagonal matrix
fixef_sigma

# By-subject random effects for the model:
VarCorr(bfm_orig)$subject$sd
# Extract by-subject random SDs and square them to obtain variances:
ranef_sigma_subj <- diag(VarCorr(bfm_orig)$subject$sd[, 1]) ^ 2
ranef_sigma_subj

# The original data consists of aggregated by-subject data, not trial-level data.
# To obtain estimates for item-level variability we use our own pilot data (see
# https://github.com/montero-melis/2018_replication_sheb-pulv2013/blob/master/1806_pilot_analysis/item-variance_estimates.R).
# The random by-item intercept is SD=0.65. However, we don't have estimates for
# by-item random slope for movement because we only ran the control condition in
# the pilot. We will assume the SD for this random slope to be the same as the
# by-subject SD for the slope of the critical interaction, which is likely to be
# an overestimate. If so, it will only make our power estimates more conservative:
ranef_sigma_item <- diag(c(0.65, 0.06)) ^ 2  # square to obtain variances
ranef_sigma_item
```



Simulate data
-------------

Simulate data for our $N_{max} = 108$:

```{r, message=FALSE}
# Simulate data
set.seed(654198461)  # make data set replicable
d <- simulate_binom(
  Nsubj = 60,
  Nitem = 104,
  fixef_means = fixef_means,
  fixef_sigma = fixef_sigma,
  ranef_sigma_subj = ranef_sigma_subj,
  ranef_sigma_item = ranef_sigma_item
)
```


The output is a data frame with the simulated data:

```{r}
head(d) %>% kable
```

This data frame contains columns that decompose each observation into the
parameters that generated it. These parameters reflect effects at three different
levels: population-, participant-, and item-level effects.
In the real data set we would only observe the actual outcome and would have
to infer the rest. So the actual data will look like this:

```{r}
d %>% select(subject : Error) %>% head %>% kable
```



Simulate sequential data collection
-----------------------------------

Our design is sequential:

1. Collect data from $N_{min}=60$ participants.
2. Compute standard $BF$ (weakly informative prior) for alternative hypothesis
   (interaction $\neq 0$) vs null hypothesis (interaction $= 0$).
3. If either $BF_{10} > 6$ or $BF_{01} > 6$, stop data collection and report
   results. Else:
4. If $N<108$, collect another batch of 12 participants and go to step 2. Else:
5. When we reach $N=108$, stop data collection, compute $BF$ and report results.

We therefore first analyze a data set of $N_{min}=60$ participants:

```{r}
d_60 <- d %>% filter(subject %in% 1 : 60)
```


Analyze and plot data (analysis pipeline)
=====================

We show the data analysis pipeline for a data set corresponding to a sample
size of $N=60$. If the Bayes factor was below our pre-determined evidence
threshold ($\frac{1}{6} < BF_{10} < 6$), then we would collect an additional
batch of 12 participants and repeat the same analysis.


Function for data analysis
--------------------------

Create a function that streamlines data processing and model fitting:

```{r}
analyse_pipe <- function(
  df,            # expects the data frame in above format
  repBF = FALSE  # compute replication BF?
  ) {
  
  df_name <- deparse(substitute(df))  # to use for filename later
  if (repBF) { df_name <- paste(df_name, "repBF", sep = "_") }
  
  # Drop superfluous columns (those that won't be in the actual data)
  df <- select(df, subject : Error)

  # coding scheme: contrast code factors and standardize numerical predictors
  contrasts(df$movement) <- contr.sum(2)
  colnames(contrasts(df$movement)) <- "arms_vs_legs"
  print(contrasts(df$movement))
  
  contrasts(df$word_type) <- contr.sum(2)
  colnames(contrasts(df$word_type)) <- "arms_vs_legs"
  print(contrasts(df$word_type))
  
  df$trial_in_exp_z <- scale(df$trial_in_exp)
  df$pos_in_trial_z <- scale(df$pos_in_trial)
  df$preced_error_z <- scale(df$preced_error)
  
  # Formula of the full model:
  formula_full <- as.formula(paste(
    "Error ~",  # DV
    "1 + movement * word_type +",  # critical manipulations and interaction
    "trial_in_exp_z + pos_in_trial_z + preced_error_z +",  # nuisance predictors
    "(1 + movement * word_type | subject) + (1 + movement | item)"  # maximal random structure
  ))
  print(formula_full)
  # Formula of the null model (remove the population-level interaction)
  formula_null <- update(formula_full, ~ . - movement : word_type)
  print(formula_null)
  
  # Priors:
  # As default, specify weakly informative priors: N(0,sigma^2 = 4) for
  # population-level (fixed) effects
  # NB: In Stan a normal distribution is specified with sigma (*not* sigma^2), see
  # https://mc-stan.org/docs/2_18/functions-reference/normal-distribution.html
  # and
  # https://stackoverflow.com/questions/52893379/stan-in-r-standard-deviation-or-variance-in-normal-distribution
  # Print to screen the priors that can be specified for full and null models:
  print(get_prior(formula_full, df))
  print(get_prior(formula_null, df))
  # Set weakly informative priors
  myprior <- set_prior("normal(0, 2)", class = "b")
  print("myprior:")
  print(myprior)
  # for replication BF, use the posterior of the re-analysis as prior for interaction:
  myprior_repBF <- c(
    myprior,
    set_prior(
      paste("normal(", mean_inter_post, ",", sd_inter_post, ")", sep = ""),
      class = "b",
      coef = "movementarms_vs_legs:word_typearms_vs_legs"
      )
    )
  print("myprior_repBF:")
  print(myprior_repBF)

  # fit null model (without interaction):
  # NB: The prior for interaction is not defined in the null model:
  bfm_null <- brm(
    formula = formula_null,
    data = df,
    prior = myprior,
    family = "bernoulli",
    iter = 15000, warmup = 2000, chains = 4,  # https://discourse.mc-stan.org/t/bayes-factor-using-brms/4469/3
    save_all_pars = TRUE  # necessary for brms::bayes_factor() later
  )
  # Model *without* interaction
  bfm_full <- update(
    bfm_null,
    formula = formula_full,
    prior = if (repBF) { myprior_repBF } else { myprior },
    )

  # pack models and data into a list and give sensible names to each object
  out <- list(bfm_full, bfm_null, df)
  names(out) <- paste(df_name, c("bfm_full", "bfm_null", "dataset"), sep = "_")

  # save list to disk:
  saveRDS(out, file = paste("data/analysis_simulated_", df_name, ".rds", sep =""))
  
  out
}
```



Fit model with weakly informative priors
----------------------------

Fit full and null models the first time and load them from disk later
(comment/uncomment accordingly):

```{r}
# sim_d_60 <- analyse_pipe(d_60)  # takes about 2.5 hours
sim_d_60 <- readRDS("data/analysis_simulated_d_60.rds")
names(sim_d_60)
```


Summary of priors (sanity check):

```{r}
prior_summary(sim_d_60[[1]])  # full model
prior_summary(sim_d_60[[2]])  # null model
```


Model summary
------------

Full model with the critical interaction:

```{r}
summary(sim_d_60[[1]])
```


Standard Bayes factor for H1 (full model) vs H0 (null model)
--------------------------

Compute Bayes factor (or load from disk if run before):

```{r}
# # Run and save to disk
# BF_bfm_d60 <- brms::bayes_factor(
#   sim_d_60[["d_60_bfm_full"]], sim_d_60[["d_60_bfm_null"]]
#   )
# saveRDS(BF_bfm_d60, "data/BF_bfm_d60.rds")

# Once run, read from disk
BF_bfm_d60 <- readRDS("data/BF_bfm_d60.rds")
```


Standard Bayes factor comparing $H_1$ (the critical interaction is not zero) to 
$H_0$ (the critical interaction is zero), based on weakly informative prior:

```{r}
BF_bfm_d60
```



Plot model estimates
--------------------

Plot all population-level estimates. Inner boxes show 50%, outer error bars 95%
credible intervals (see detailed 
[plot explanation here](https://strengejacke.github.io/sjPlot/articles/plot_model_estimates.html#bayesian-models-fitted-with-stan)): 

```{r sjplot_model}
sjPlot::plot_model(
  sim_d_60[[1]], transform = NULL, prob.outer = .95, sort.est = TRUE,
  vline.color = "gray", title = "Log-odds of error",
  axis.labels = c(  # Careful: indep of sort.est, the order is simply specified bottom to top!
    "word type (arm- vs leg-related)",
    "movement condition (arms vs legs)",
    "preceding error in trial",
    "word position in trial",
    "trial in experiment",
    "movement-by-word type interaction"
    )
  ) +
  theme_classic()
```


Plot the interaction effect:

```{r}
plot(marginal_effects(sim_d_60[[1]], effects = "movement:word_type"),
     theme = theme_classic())
```


Replication Bayes factor (after Verhagen and Wagenmakers, 2014)
---------------------------------------------------------------

If the standard BF (here above) is greater than the pre-determined evidence
threshold or if we have reached $N_{max}=96$, then we also compute the replication
Bayes factor $BF_{rep}$ (Verhagen and Wagenmakers, 2014).
Since in this simulated data set our standard 
$BF = `r round(BF_bfm_d60$bf)` \geq 6$, we do compute the $BF_{rep}$.

For $BF_{rep}$ we use as the prior for the interaction coefficient the posterior
distribution from the model fitted to the original data. We specify this as
a normal distribution (see "Set up workspace" for this prior and 
"Function for data analysis" for the actual fitting).


### Fit models with appropriate prior for repBF:

Fit full and null models the first time and load them from disk later
(comment/uncomment accordingly):

```{r}
# sim_d_60_BFrep <- analyse_pipe(d_60, repBF = TRUE)  # takes about 2  hours
sim_d_60_BFrep <- readRDS("data/analysis_simulated_d_60_repBF.rds")
names(sim_d_60_BFrep)
```

### Check priors and model summary

Summary of priors:

```{r}
prior_summary(sim_d_60_BFrep[[1]])  # full model
prior_summary(sim_d_60_BFrep[[2]])  # null model
```

Model summary (full model with interaction)

```{r}
summary(sim_d_60_BFrep[[1]])
```



### Replication BF ($BF_{rep}$)

Compute replication Bayes factor (or load from disk if run before):

```{r}
# # Run and save to disk
# BFrep_bfm_d60 <- brms::bayes_factor(
#   sim_d_60_BFrep[[1]], sim_d_60_BFrep[[2]]
#   )
# saveRDS(BFrep_bfm_d60, "data/BFrep_bfm_d60.rds")

# Once run, read from disk
BFrep_bfm_d60 <- readRDS("data/BFrep_bfm_d60.rds")
```

$BF_{rep}$:

```{r}
BFrep_bfm_d60
```

The replication BF is 
$BF_{rep} = `r round(BFrep_bfm_d60$bf)` \geq 6$.



Session info
============

```{r}
sessionInfo()
```

